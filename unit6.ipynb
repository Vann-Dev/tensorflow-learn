{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-25 03:04:45.772762: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-01-25 03:04:45.817709: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-01-25 03:04:45.817784: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-01-25 03:04:45.818905: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-01-25 03:04:45.830063: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-25 03:04:46.406840: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import requests\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-25 03:04:47.236451: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:274] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model('outputs/model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "url = 'https://raw.githubusercontent.com/MicrosoftDocs/tensorflow-learning-path/main/intro-keras/predict-image.png'\n",
    "\n",
    "with Image.open(requests.get(url, stream=True).raw) as image:\n",
    "  X = np.asarray(image, dtype=np.float32).reshape((-1, 28, 28)) / 255.0\n",
    "\n",
    "plt.figure()\n",
    "plt.axis('off')\n",
    "plt.imshow(X.squeeze(), cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_map = {\n",
    "  0: 'T-Shirt',\n",
    "  1: 'Trouser',\n",
    "  2: 'Pullover',\n",
    "  3: 'Dress',\n",
    "  4: 'Coat',\n",
    "  5: 'Sandal',\n",
    "  6: 'Shirt',\n",
    "  7: 'Sneaker',\n",
    "  8: 'Bag',\n",
    "  9: 'Ankle Boot',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 111ms/step\n",
      "Predicted class: Ankle Boot\n"
     ]
    }
   ],
   "source": [
    "predicted_vector = model.predict(X)\n",
    "predicted_index = np.argmax(predicted_vector)\n",
    "predicted_name = labels_map[predicted_index]\n",
    "\n",
    "print(f'Predicted class: {predicted_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T-Shirt -> 0.000\n",
      "Trouser -> 0.000\n",
      "Pullover -> 0.000\n",
      "Dress -> 0.000\n",
      "Coat -> 0.000\n",
      "Sandal -> 0.021\n",
      "Shirt -> 0.000\n",
      "Sneaker -> 0.081\n",
      "Bag -> 0.006\n",
      "Ankle Boot -> 0.892\n"
     ]
    }
   ],
   "source": [
    "probs = tf.nn.softmax(predicted_vector.reshape((-1,)))\n",
    "for i,p in enumerate(probs):\n",
    "    print(f'{labels_map[i]} -> {p:.3f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
